---
title: "Arne report"
author: "Lukáš Hejtmánek"
date: "9 August 2018"
output: html_document
---

```{r setup, include=FALSE}
library(ggplot2)
library(ez)
library(Hmisc)
library(dplyr)
library(reshape2)
library(broom)
library(knitr)
library(brainvr.R)
library(restimoter)
library(papaja)

source("../Scripts/loading.R")
source_folder("../TwoWorlds")
source('../Scripts/analysis-helpers.R')
sop_all <- read.table("../sop.csv", sep=";", header = T, stringsAsFactors = F)
walk_all <- read.table("../walk.csv", sep=";", header = T, stringsAsFactors = F)
walk_all$learning.condition <- walk_all$condition
walk_all$learning.condition <- recode(walk_all$learning.condition, "real-real" = "Real", "ve-real" = "Desktop", "vr-real" = "Treadmill VR", "real-vr" = "Real", "vr-vr" = "Treadmill VR")
sop_all$learning.condition <- sop_all$condition
sop_all$testing.condition <- sop_all$condition
sop_all$learning.condition <- recode(sop_all$learning.condition, "real-real" = "Real", "ve-real" = "Desktop", "vr-real" = "Treadmill VR", "real-vr" = "Real", "vr-vr" = "Treadmill VR")
sop_all$testing.condition <- recode(sop_all$testing.condition, "real-real" = "Real", "ve-real" = "Real", "vr-real" = "Real", "real-vr" = "Treadmill VR", "vr-vr" = "Treadmill VR")

conference_walk_all <- walk_all %>% filter(condition %in% c("vr-real", "real-real", "ve-real"))
conference_sop_all <- sop_all %>% filter(condition %in% c("vr-real", "real-real", "ve-real"))

#green, violet, blue, yellow, pink, dark blue
estimote_pal <- c('#b6d6c1', '#54003d','#93d5f6','#d5d215','#f3aacb','#2d2556')
theme_set(theme_minimal())

condition_all_sums <- conference_walk_all %>% 
  group_by(exp_block_id, id, learning.condition) %>% 
  summarise(sum.distance = sum(min_norm_distance, na.rm = T), 
            sum.errors = sum(errors, na.rm = T),
            mean.distance = mean(min_norm_distance, na.rm = T),
            mean.error = mean(errors, na.rm = T))

block_measure <- function(df, value){
  df_wide <- dcast(df, learning.condition + id ~ exp_block_id, value.var = value)
  colnames(df_wide) <- c("learning.condition","id","block1", "block2","block3","block4","block5","block6")
  df_wide %>% 
    group_by(learning.condition) %>%
    summarise(block1.mean  = mean(block1, na.rm = T),
              block3.mean = mean(block3, na.rm = T),
              block4.mean = mean(block4, na.rm = T),
              block34.diff = mean((block3-block4)/(block4+block3), na.rm = T),
              block34.se  = sqrt(var((block3-block4)/(block4+block3), na.rm = T)/sum(!is.na(block3-block4))),
              block14.diff = mean((block1-block4)/(block1+block4), na.rm = T),
              block14.se = sqrt(var((block1-block4)/(block1+block4), na.rm = T)/sum(!is.na(block1-block4)))
  )
}

```

Unless stated otherwise, I ran all tests on the normalised distance and time statistics. Errors and pointing information is not normalised, as they are the same in all conditions. 

I only selected those "important" comparisons - therefore Desktop to Real, Treadmill VR to real and Real to real. Anovas and other comparisons are run only on these.

## Descriptives
In normalised distance we can see that people in different conditions start fairly at the same level of performance (difference between learnign conditions is not significant `r apa_print(aov(min_norm_distance ~ learning.condition, conference_walk_all[conference_walk_all$exp_block_id == 1, ]))$statistic$learning_condition`)

```{r, echo=F, warning=F}
make_graph(conference_walk_all, "learning.condition", "min_norm_distance", "exp_block_id") + 
  ylab("Average normalised trial distance") + xlab("condition") + 
  scale_fill_manual(values=estimote_pal,"Block ID")

ggplot(conference_walk_all, aes(x = exp_block_id, y = min_norm_distance, color = factor(learning.condition))) +
  stat_summary(fun.data=mean_cl_normal,position=position_dodge(width=0.1), width = 0.2, geom="errorbar") + 
  stat_summary(fun.y=mean,position=position_identity(), size = 1, geom="line") + 
  geom_vline(xintercept = 3.5, linetype=4) +
  ylab("Average normalised trial distance") + xlab("Block") + 
  scale_color_manual(values=estimote_pal,"Condition") + guides(fill=F)
```

There is difference in normalised times in all conditions in the first block (`r apa_print(aov(min_norm_time ~ learning.condition, conference_walk_all[conference_walk_all$exp_block_id == 1, ]))$statistic$learning_condition`)). Probably due to learning issues with the treadmill. Threre is no significant difference between desktop and real world learning in normalised times (`r apa_print(t.test(min_norm_time ~ learning.condition, conference_walk_all[conference_walk_all$exp_block_id == 1 & conference_walk_all$learning.condition %in% c("Desktop", "Real"), ]))$statistic`))

```{r, echo=F}
make_graph(conference_walk_all, "learning.condition", "min_norm_time", "exp_block_id")+ 
  ylab("Average normalised trial duration") + xlab("condition") + 
  scale_fill_manual(values=estimote_pal, "Block ID")
```

And we don't have any significant difference in number of errors in the first block (`r apa_print(aov(errors ~ learning.condition, conference_walk_all[conference_walk_all$exp_block_id == 1, ]))$statistic$learning_condition`)).

```{r, echo=F}
make_graph(conference_walk_all, "learning.condition", "errors", "exp_block_id")+ 
  ylab("Average number of errors") + xlab("condition") + 
  scale_fill_manual(values=estimote_pal," Block ID")

ggplot(conference_walk_all, aes(x = exp_block_id, y = errors, color = factor(learning.condition))) +
  stat_summary(fun.data=mean_cl_normal,position=position_dodge(width=0.1), width = 0.2, geom="errorbar") + 
  stat_summary(fun.y=mean,position=position_identity(), size = 1, geom="line") + 
  geom_vline(xintercept = 3.5, linetype=4) +
  ylab("Number of mistakes in office decision") + xlab("Block number") + 
  scale_color_manual(values=estimote_pal, "Condition")
```

We can clearly see differences in the progression of the learning slopes, but as you pointed out many times, as they are not linear, we could benefit from non linear modeling. I hope Mike and professor Ferer will help us with that.

But I can look at either pure changes between block 3-4 or 1-4 or those calculations that you proposed as a (block4-block3)/(block3+block4) measurements.

```{r, echo=F}
df_wide_errors <- dcast(condition_all_sums, learning.condition + id ~ exp_block_id, value.var = "sum.errors")
df_wide_distance <- dcast(condition_all_sums, learning.condition + id ~ exp_block_id, value.var = "mean.distance")
colnames(df_wide_errors) <- c("learning.condition","id","block1", "block2","block3","block4","block5","block6")
colnames(df_wide_distance) <- c("learning.condition","id","block1", "block2","block3","block4","block5","block6")

df_wide_errors$block14 <- (df_wide_errors$block1-df_wide_errors$block4)/(df_wide_errors$block1+df_wide_errors$block4)
df_wide_errors$block34 <- (df_wide_errors$block3-df_wide_errors$block4)/(df_wide_errors$block3+df_wide_errors$block4)
df_wide_distance$block14 <- (df_wide_distance$block1-df_wide_distance$block4)/(df_wide_distance$block1+df_wide_distance$block4)
df_wide_distance$block34 <- (df_wide_distance$block3-df_wide_distance$block4)/(df_wide_distance$block3+df_wide_distance$block4)

df_errors <- block_measure(condition_all_sums, "sum.errors")
df_distance <- block_measure(condition_all_sums, "mean.distance")

block_t_test <- function(df, block1, block2, value){
  df <- df %>% filter(exp_block_id %in% c(block1,block2))
  mean.na <- function(data){return(mean(data, na.rm = T))}
  df_wide <- dcast(df, learning.condition + id ~ exp_block_id, value.var = value, fun.aggregate = mean.na)
  colnames(df_wide) <- c("learning.condition","id", "block1","block2")
  df_wide %>% group_by(learning.condition) %>% do(tidy(t.test(.$block1, .$block2, paired = T)))
}

ez_prepare_block <- function(df, blocks){
  filtered_data <- df[df$exp_block_id %in% blocks, ]
  filtered_data <- filtered_data[complete.cases(filtered_data),]
  has_all <- filtered_data %>% group_by(id) %>% select(id, "exp_block_id") %>% unique() %>% count
  has_all <- has_all %>% filter(n == 2)
  filtered_data <- filtered_data %>% filter(id %in% has_all$id)
  filtered_data$exp_block_id <- factor(filtered_data$exp_block_id)
  return(filtered_data)
}

clean_walk_14 <- ez_prepare_block(conference_walk_all, c(1,4))
clean_walk_34 <- ez_prepare_block(conference_walk_all, c(3,4))
```

## Block improvement from block 1 to block 4

### Distance
All conditions improved from the first to fourth block in both distance walked and errors in decisions. Paired t-tests show that both Treadmill and Real world learning conditions led to improved performance from 1-4, but Desktop did not. All conditions show significant improvement in number of errors from block 1 to 4.

```{r, echo=F}
df_dist <- block_t_test(conference_walk_all, 1, 4,"min_norm_distance")[,c(1,4)]
df_error <- block_t_test(conference_walk_all, 1, 4,"errors")[,c(1,4)]
df14 <- merge(df_dist, df_error, by = "learning.condition")
colnames(df14) <- c("learning condition", "p-value distance improvement", "p-value errors improvement")
kable(df14)
```

But anova shows no significant difference in the improvement between groups for distance (`r apa_print(aov(block14 ~ learning.condition, df_wide_distance))$statistic$learning_condition`). This might be due to quite large variability in the sample.

```{r, echo=F}
ggplot(df_distance, aes(x = learning.condition, y = block14.diff, fill = learning.condition)) + 
  geom_bar(stat = 'identity', position="dodge") + 
  geom_errorbar(aes(ymin=block14.diff-block14.se, ymax=block14.diff+block14.se), width=.2, position=position_dodge(.9)) +
  scale_fill_manual(values = estimote_pal) +
  ylab("Mean normalised distance improvement from block 1 to 4") + xlab("Learning condition")  + guides(fill=F)
```

### Errors
Unlike for distance, anova reveals significant difference in number of errors improvement from block 1 to block 4 between different learning conditions (`r apa_print(aov(block14 ~ learning.condition, df_wide_errors))$statistic$learning_condition`). 

Runnign Tukey's post hoc on the distance shows that this is originating from the difference between Desktop and the Real world, with Treadmill not being significantly different from either of them.

```{r, echo=F}
kable(TukeyHSD(x=aov(block14 ~ learning.condition, df_wide_errors), conf.level=0.95)$learning.condition[, c(1,4)])
```

```{r, echo=F}
ggplot(df_errors, aes(x = learning.condition, y = block14.diff, fill = learning.condition)) + 
  geom_bar(stat = 'identity', position="dodge") + 
  geom_errorbar(aes(ymin=block14.diff-block14.se, ymax=block14.diff+block14.se), width=.2, position=position_dodge(.9)) +
  scale_fill_manual(values = estimote_pal) +
  ylab("Mean sum of errors improvement from block 1 to 4") + xlab("Learning condition")  + guides(fill=F)
```

## Block performance improvement from block 3 to block 4

Everybody's distance performance (including Real to Real condition) gets a little bit worse from 3 to 4. But this is not significant when computed using paired t-tests, although it is marginally worse in the desktop version. But all conditions show decrease in the number of errors from block 3 to 4.

```{r, echo=F}
df_dist <- block_t_test(conference_walk_all, 3, 4,"min_norm_distance")[,c(1,4)]
df_error <- block_t_test(conference_walk_all, 3, 4,"errors")[,c(1,4)]
df34 <- merge(df_dist, df_error, by = "learning.condition")
colnames(df34) <- c("learning.condition", "p-value distance improvement", "p-value errors improvement")
kable(df34)
```

### Distance

Comparing the block improvement in different conditions using anovas, we see marginally significant difference in the improvement between groups for distance (`r apa_print(aov(block34 ~ learning.condition, df_wide_distance))$statistic$learning_condition`).

```{r, echo=F}
ggplot(df_distance, aes(x = learning.condition, y = block34.diff, fill = learning.condition)) + 
  geom_bar(stat = 'identity', position="dodge") + 
  geom_errorbar(aes(ymin=block34.diff-block34.se, ymax=block34.diff+block34.se), width=.2, position=position_dodge(.9)) +
  scale_fill_manual(values = estimote_pal) +
  ylab("Mean normalised distance improvement from block 3 to 4") + xlab("Learning condition")  + guides(fill=F)
```

Within subject anova for distance improvement between 3 and 4 shows significant interaction effect and marginally significant effect of learning condition and block on distance.
```{r, warning = F, echo=F, message=F}
aov_block_dist_34 <- ezANOVA(
  data = clean_walk_34,
  dv = min_norm_distance, 
  wid = id,
  within = exp_block_id,
  between = learning.condition, 
  type = 3)
kable(aov_block_dist_34)

ggplot(clean_walk_34, aes(x = as.numeric(exp_block_id), y = min_norm_distance, color = factor(learning.condition))) +
  stat_summary(fun.data=mean_cl_normal,position=position_dodge(width=0.1), width = 0.2, geom="errorbar") + 
  stat_summary(fun.y=mean,position=position_identity(), size = 1, geom="line") + 
  ylab("Average normalised distance") + xlab("Experimental block") + 
  scale_color_manual(values = estimote_pal, "Learning condition")
```

### Errors

We can see significant differences between different conditions in error rate improvement from block 3 to 4 when running independent anova (`r apa_print(aov(block34 ~ learning.condition, df_wide_errors))$statistic$learning_condition`).

Post hoc tests show significant difference between Real and Desktop and marginally for Treadmill and Desktop.
```{r, echo=F}
kable(TukeyHSD(x=aov(block34 ~ learning.condition, df_wide_errors), conf.level=0.95)$learning.condition[, c(1,4)])
```

```{r, echo=F}
ggplot(df_errors, aes(x = learning.condition, y = block34.diff, fill = learning.condition)) + 
  geom_bar(stat = 'identity', position="dodge") + 
  geom_errorbar(aes(ymin=block34.diff-block34.se, ymax=block34.diff+block34.se), width=.2, position=position_dodge(.9)) +
  scale_fill_manual(values = estimote_pal) +
  ylab("Mean sum of errors improvement after switch")+ xlab("Learning condition") + guides(fill=F)
```

Running within subjects anova for block 3-4 number of errors shows significant effect of both condition and block, but unlike in distance improvement, their interaction doesn't seem to have an effect on error rate improvement.
```{r, warning = F, echo=F, message=F}
aov_block_err_34 <- ezANOVA(
  data = clean_walk_34,
  dv = errors, 
  wid = id,
  within = exp_block_id,
  between = condition,
  type = 3)
kable(aov_block_err_34)

ggplot(clean_walk_34, aes(x = as.numeric(exp_block_id), y = errors, color = factor(condition))) +
  stat_summary(fun.data=mean_cl_normal,position=position_dodge(width=0.1), width = 0.2, geom="errorbar") + 
  stat_summary(fun.y=mean,position=position_identity(), size = 1, geom="line") + 
  ylab("Average number of errors") + xlab("Experimental block") + 
  scale_color_manual(values = estimote_pal, "Learning condition")
```


## Summary
We see effect of learning condition (blocks 1-3) on performance in block 4. We also see 

Participant's performance in distance from block 3-4 gets slightly worse after the switch, but their number of errors decrease. It can mean that they know which door are correct, but they are unsure in how to get to them, showing some level of memory transfer, but not necessarily spatial knowledge transfer.