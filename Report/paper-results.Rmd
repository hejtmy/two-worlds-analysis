---
title: "R Notebook"
output: github_document
---

```{r setup, include=FALSE}
#needs lme and car in the top because of the recode
library(car)
library(lme4)
library(lmerTest)
library(ggplot2)
library(ez)
library(Hmisc)
library(dplyr)
library(reshape2)
library(broom)
library(knitr)
library(papaja)
library(googlesheets)

source("../Scripts/paper-prepare.R")
source("helpers/block-t-test-improvement.R")
source("helpers/block-t-test.R")
source("helpers/block-measure.R")

settings <- load_google_sheets()
df_participants <- settings$participants
df_participants <- df_participants %>% mutate(condition=paste0(First.phase,"-",Second.phase))
df_participants <- df_participants %>% filter(condition %in% c("vr-real", "real-real", "ve-real"))
overview <- settings$versions
overview <- overview %>% mutate(condition=paste0(First.phase,"-",Second.phase))
overview <- overview %>% filter(condition %in% c("vr-real", "real-real", "ve-real"))

#green, violet, blue, yellow, pink, dark blue
estimote_pal <- c('#b6d6c1', '#54003d','#93d5f6','#d5d215','#f3aacb','#2d2556')
theme_set(theme_minimal())

condition_all_sums <- sub_walk_all %>% 
  group_by(exp_block_id, id, learning.condition) %>% 
  summarise(sum.distance = sum(min_norm_distance, na.rm = T), 
            sum.errors = sum(errors, na.rm = T),
            mean.distance = mean(min_norm_distance, na.rm = T),
            mean.error = mean(errors, na.rm = T))


df_errors <- block_measure(condition_all_sums, "sum.errors")
df_distance <- block_measure(condition_all_sums, "mean.distance")

df_wide_errors <- dcast(condition_all_sums, learning.condition + id ~ exp_block_id, value.var = "sum.errors")
df_wide_distance <- dcast(condition_all_sums, learning.condition + id ~ exp_block_id, value.var = "mean.distance")
colnames(df_wide_errors) <- c("learning.condition","id","block1", "block2","block3","block4","block5","block6")
colnames(df_wide_distance) <- c("learning.condition","id","block1", "block2","block3","block4","block5","block6")
df_wide_errors$block34 <- (df_wide_errors$block3-df_wide_errors$block4)/(df_wide_errors$block3+df_wide_errors$block4)
df_wide_distance$block34 <- (df_wide_distance$block3-df_wide_distance$block4)/(df_wide_distance$block3+df_wide_distance$block4)

knitr::opts_chunk$set(echo=F, warning = F, message = F)

```

# Methods

## Measures
We calculated participantsâ€™ walked distance in the building, time spent in each task and number of incorrectly visited doors. The conditions were not perfectly comparable in their measured distance and time, with the VR trials taking a little bit longer in both time and distance than the real world condition. We therefore min-normalised the distance traveled and the time for each task and environment  by dividing the measure by any participant's performance for that trial. We calculated all statistics on these normalised measures. 

There was no difference between conditions at the start of the experiment in normalised distance (`r apa_print(aov(min_norm_distance ~ learning.condition, sub_walk_all[sub_walk_all$exp_block_id == 1, ]))$statistic$learning_condition`), nor in number errors (`r apa_print(aov(errors ~ learning.condition, sub_walk_all[sub_walk_all$exp_block_id == 1, ]))$statistic$learning_condition`), but there is a significant difference in normalised time (`r apa_print(aov(min_norm_time ~ learning.condition, sub_walk_all[sub_walk_all$exp_block_id == 1, ]))$statistic$learning_condition`)), due to VR taking longer times to get used to (and therefore having longer normalised trial times at the start).

## Participants
```{r}
finished <- overview %>% group_by(condition) %>% count(finished)
finished <- dcast(finished, condition~finished)
finished$percent <- round(finished$yes/(finished$yes+finished$no), 2)
is_ok <- overview %>% filter(finished=="yes") %>% group_by(condition) %>% count(is_ok)
is_ok <- dcast(is_ok, condition~is_ok)
is_ok$percent <- round(is_ok$yes/(is_ok$yes+is_ok$no), 2)
```
A total of `r sum(overview$is_ok == "yes", na.rm=T)` (M = `r round(mean(df_participants[df_participants$finished == "yes",]$age, na.rm=T),1)`, SD = `r round(sd(df_participants[df_participants$finished == "yes",]$age, na.rm=T), 1)`) undergraduate students at UC Davis particiapted in the study in exchange for a study credit. Each students was randomly assigned a condition and a randomised set of goals. `r sum(finished$no)` participants didn't finish due to motion sickness and `r sum(is_ok$no)` were removed due to a technical failure of the real world tracking systen. Only `r finished[finished$condition == "vr-real","percent"] * 100` percent the students being able to finish VR to Real world condition.

# Results

First we wanted to assess that there is going to be some level of transfer in all conditions. If we would assume no transfer to happen, we should observe same performance in the real world testing in 1st, 2nd and 3rd block after the switch to be similar in performance as the 1st, 2nd and 3rd block in the real world learning group. But all conditions (except desktop in distance) show better performance after the switch (see table XXX) than in the first trial, suggesting some level of transfer happening in all learning conditions.
```{r}
df <- data.frame(condition=rep("",3),dist=rep("",3), err=rep("",3), stringsAsFactors = F)
df_dist <- block_t_test_improvement(sub_walk_all, 1, 4,"min_norm_distance")
df_error <- block_t_test_improvement(sub_walk_all, 1, 4,"errors")
for(i in 1:length(names(df_dist))){
  name <- names(df_dist)[i]
  df[i,"condition"] <- name
  df[i, "dist"] <- apa_print(df_dist[[name]])$full_result
  df[i, "err"] <- apa_print(df_error[[name]])$full_result
}
colnames(df) <- c("Learning condition", "Distance improvement", "Errors improvement")
df$`Learning condition` <- dplyr::recode(df$`Learning condition`, "real-real" = "Real", "ve-real" = "Desktop", "vr-real" = "Treadmill VR", "real-vr" = "Real", "vr-vr" = "Treadmill VR")
kable(df, caption="Paired T test comparing individual performance improvement from block 1-4 in different conditions")
```

Looking at the progression in distance improvements and error improvements over the course of the experiment, we can see that all conditions show progressive improvement which is only hindered by the switch in the desktop learning condition (see fig. XXX and fig. XXX), but in the Treadmill condition we see constant improvement unobstructed by the environmrnt switch.
```{r}
ggplot(sub_walk_all, aes(x = exp_block_id, y = min_norm_distance, color = factor(learning.condition))) +
  stat_summary(fun.data=mean_cl_normal,position=position_dodge(width=0.1), width = 0.5, geom="errorbar") + 
  stat_summary(fun.y=mean,position=position_identity(), size = 1.25, geom="line") + 
  geom_vline(xintercept = 3.5, linetype=4) +
  ylab("Average normalised trial distance") + xlab("Block") + 
  scale_color_manual(values=estimote_pal,"Learning condition") + guides(fill=F)

ggplot(sub_walk_all, aes(x = exp_block_id, y = errors, color = factor(learning.condition))) +
  stat_summary(fun.data=mean_cl_normal,position=position_dodge(width=0.1), width = 0.5, geom="errorbar") + 
  stat_summary(fun.y=mean,position=position_identity(), size = 1.25, geom="line") + 
  geom_vline(xintercept = 3.5, linetype=4) +
  ylab("Number of mistakes in office decision") + xlab("Block number") + 
  scale_color_manual(values=estimote_pal, "Learning condition")
```

Participant's performance in the first pre-switch phase shows different rates of learning rate (see table XX). There is no significant difference between different modalities in distance performance before the switch `r apa_print(aov(min_norm_distance ~ learning.condition, only_blocks(sub_walk_all, 3)))$full_result`, but the performance across groups differs in errors `r  apa_print(aov(errors ~ learning.condition, only_blocks(sub_walk_all, 3)))$full_result`.

```{r}
learning_slopes_distance <- lmer(min_norm_distance ~ learning.condition*exp_block_id + (1 | id/exp_block_id), data = sub_walk_all[sub_walk_all$exp_block_id %in% 1:3,])
tab_distance <- mixed_table_report(learning_slopes_distance)

learning_slopes_errors <- lmer(errors ~ learning.condition*exp_block_id + (1 | id/exp_block_id), data = sub_walk_all[sub_walk_all$exp_block_id %in% 1:3,])
tab_errors <- mixed_table_report(learning_slopes_errors)

tab <- merge(tab_distance[,c(3,4)], tab_errors[,c(3,4)], by = "names")
tab$names <- c("Intercept", "Block number", "Learning condition", "Block - Learning condition interaction")
colnames(tab) <- c("Predictor", "Significance for distance improvement", "Significance for error improvement")
kable(tab)
#ggplot(sub_walk_all[sub_walk_all$exp_block_id %in% 1:3,], aes(exp_block_id, min_norm_distance, color=learning.condition)) + geom_point() + geom_smooth(method="lm", se=F)
#ggplot(sub_walk_all[sub_walk_all$exp_block_id %in% 1:3,], aes(exp_block_id, errors, color=learning.condition)) + geom_point() + geom_smooth(method="lm", se=F)

```

### After modality switch performance change
Anova doesn't show a significant difference between groups in the pre-switch block (`r apa_print(aov(min_norm_distance ~ learning.condition, sub_walk_all[sub_walk_all$exp_block_id == 3,]))$statistic$learning_condition`), but there is a significant difference between distance performance in the post-switch block (`r apa_print(aov(min_norm_distance ~ learning.condition, sub_walk_all[sub_walk_all$exp_block_id == 4,]))$statistic$learning_condition`).

After the modality switch, we can see a significant difference between distance performance (`r apa_print(aov(min_norm_distance ~ learning.condition, sub_walk_all[sub_walk_all$exp_block_id == 4,]))$statistic$learning_condition`) and errors as well (`r apa_print(aov(errors ~ learning.condition, sub_walk_all[sub_walk_all$exp_block_id == 4,]))$statistic$learning_condition`), with groups learning on the treadmill or desktop performing worse than those learning in the real world. This difference among conditions post-switch is still apparent in the 2nd block after the switch in number of errors `r  apa_print(aov(errors ~ learning.condition, only_blocks(sub_walk_all, 5)))$full_result` and marginally in distance `r apa_print(aov(min_norm_distance ~ learning.condition, only_blocks(sub_walk_all, 5)))$full_result`, but disappears in the last testing block for both errors `r apa_print(aov(errors ~ learning.condition, only_blocks(sub_walk_all, 6)))$full_result` and distance `r apa_print(aov(min_norm_distance ~ learning.condition, only_blocks(sub_walk_all, 6)))$full_result`.


Mixed effect models with individual random effect also show significant effect of the of the learning condition on rate of improvement from pre-switch to post-switch block (See table XXX ).

```{r}
learning_slopes_distance <- lmer(min_norm_distance ~ learning.condition*exp_block_id + (1 | id/exp_block_id), data = only_blocks(sub_walk_all, 3:4))
tab_distance <- mixed_table_report(learning_slopes_distance)

learning_slopes_errors <- lmer(errors ~ learning.condition*exp_block_id + (1 | id/exp_block_id), data = only_blocks(sub_walk_all, 3:4))
tab_errors <- mixed_table_report(learning_slopes_errors)

tab <- merge(tab_distance[,c(3,4)], tab_errors[,c(3,4)], by = "names")
tab$names <- c("Intercept", "Block number", "Learning condition", "Block - Learning condition interaction")
colnames(tab) <- c("Predictor", "Significance for distance improvement", "Significance for error improvement")
kable(tab)
```

Running separate pairwise t-tests to see individual performance change from pre-switch to post-switch block, we see significant improvement in errors made across all conditions, and marginally significant worsening in distance performance in the desktop condition.
```{r, echo=F}
df <- data.frame(condition=rep("",3),dist=rep("",3), err=rep("",3), stringsAsFactors = F)
df_dist <- block_t_test_improvement(sub_walk_all, 3, 4,"min_norm_distance")
df_error <- block_t_test_improvement(sub_walk_all, 3, 4,"errors")
for(i in 1:length(names(df_dist))){
  name <- names(df_dist)[i]
  df[i,"condition"] <- name
  df[i, "dist"] <- apa_print(df_dist[[name]])$full_result
  df[i, "err"] <- apa_print(df_error[[name]])$full_result
}
colnames(df) <- c("Learning condition", "Distance improvement", "Errors improvement")
df$`Learning condition` <- dplyr::recode(df$`Learning condition`, "real-real" = "Real", "ve-real" = "Desktop", "vr-real" = "Treadmill VR", "real-vr" = "Real", "vr-vr" = "Treadmill VR")
kable(df, caption="Paired T test comparing individual performance improvement from pre switch block to post-switch block in different conditions")
```

We can see that all participants improved in the errors made, but neigher group is significantly worse in the post-switch block in the path travelled (although participants who learned on the desktop performed slightly worse, but the significance is only marginal).

### Personal 
To assess the level of performance change form directly before and after the switch, we calculated a score personal improvement as (block3-block4)/(block3+block4)Â´. This allowed us to directly comapre the percentual improvement or deterioration from pre-switch block to the post-switch one.

```{r, echo=F}
ggplot(df_distance, aes(x = learning.condition, y = block34.diff, fill = learning.condition)) + 
  geom_bar(stat = 'identity', position="dodge") + 
  geom_errorbar(aes(ymin=block34.diff-block34.se, ymax=block34.diff+block34.se), width=.2, position=position_dodge(.9)) +
  scale_fill_manual(values = estimote_pal) +
  ylab("Mean normalised distance improvement from block 3 to 4") + xlab("Learning condition")  + guides(fill=F)

ggplot(df_errors, aes(x = learning.condition, y = block34.diff, fill = learning.condition)) + 
  geom_bar(stat = 'identity', position="dodge") + 
  geom_errorbar(aes(ymin=block34.diff-block34.se, ymax=block34.diff+block34.se), width=.2, position=position_dodge(.9)) +
  scale_fill_manual(values = estimote_pal) +
  ylab("Mean sum of errors improvement after switch")+ xlab("Learning condition") + guides(fill=F)
```

Comparing the perfomance change in different conditions using anovas, we see marginally significant difference between groups in the distance improvement (`r apa_print(aov(block34 ~ learning.condition, df_wide_distance))$statistic$learning_condition`), but significant differences in error rate improvement (`r apa_print(aov(block34 ~ learning.condition, df_wide_errors))$statistic$learning_condition`). This is consistent with the mixed model result which poited at interaction between block and learning condition.

Tukey post-hoc tests show significant difference between error rate improvement between the group that leardned in the real world and that which learned on the desktop.
```{r, echo=F}
kable(tukey_report(TukeyHSD(x=aov(block34 ~ learning.condition, df_wide_errors), conf.level=0.95)$learning.condition[, c(1,4)]))
```


### Something about pointing?


## Summary
We can see different rates of learning speed across different conditions, with significan differences between groups in their performance after the first phase witt the real world learning group performing the best, but only significanly different from group learning on the desktop. All conditions show some level of transfer, demonstrated both by general improvement from the first block to the fourth, as well as decreased errors in desktop and treadmill VR group after the switch to the real environment.
