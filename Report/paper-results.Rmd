---
title: "R Notebook"
output: github_document
---

```{r setup, include=FALSE}
#needs lme and car in the top because of the recode
library(car)
library(lme4)
library(lmerTest)
library(ggplot2)
library(ez)
library(Hmisc)
library(dplyr)
library(reshape2)
library(broom)
library(knitr)
library(papaja)
library(googlesheets)

source("../Scripts/paper-prepare.R")
source("helpers/block-t-test-improvement.R")
source("helpers/block-t-test.R")
source("helpers/block-measure.R")

settings <- load_google_sheets()
df_participants <- settings$participants
df_participants <- df_participants %>% mutate(condition=paste0(First.phase,"-",Second.phase))
df_participants <- df_participants %>% filter(condition %in% c("vr-real", "real-real", "ve-real"))
overview <- settings$versions
overview <- overview %>% mutate(condition=paste0(First.phase,"-",Second.phase))
overview <- overview %>% filter(condition %in% c("vr-real", "real-real", "ve-real"))

#green, violet, blue, yellow, pink, dark blue
estimote_pal <- c('#b6d6c1', '#54003d','#93d5f6','#d5d215','#f3aacb','#2d2556')
theme_set(theme_minimal())

condition_all_sums <- sub_walk_all %>% 
  group_by(exp_block_id, id, learning.condition) %>% 
  summarise(sum.distance = sum(min_norm_distance, na.rm = T), 
            sum.errors = sum(errors, na.rm = T),
            mean.distance = mean(min_norm_distance, na.rm = T),
            mean.error = mean(errors, na.rm = T))


df_errors <- block_measure(condition_all_sums, "sum.errors")
df_distance <- block_measure(condition_all_sums, "mean.distance")

df_wide_errors <- dcast(condition_all_sums, learning.condition + id ~ exp_block_id, value.var = "sum.errors")
df_wide_distance <- dcast(condition_all_sums, learning.condition + id ~ exp_block_id, value.var = "mean.distance")
colnames(df_wide_errors) <- c("learning.condition","id","block1", "block2","block3","block4","block5","block6")
colnames(df_wide_distance) <- c("learning.condition","id","block1", "block2","block3","block4","block5","block6")
df_wide_errors$block34 <- (df_wide_errors$block3-df_wide_errors$block4)/(df_wide_errors$block3+df_wide_errors$block4)
df_wide_distance$block34 <- (df_wide_distance$block3-df_wide_distance$block4)/(df_wide_distance$block3+df_wide_distance$block4)

knitr::opts_chunk$set(echo=F, warning = F, message = F)

```

# Methods

## Measures
We calculated participantsâ€™ walked distance in the building, time spent in each task and number of incorrectly visited doors. The conditions were not perfectly comparable in their measured distance and time, with the VR trials taking a little bit longer in both time and distance than the real world condition. We therefore min-normalised the distance traveled and the time for each task and environment  by dividing the measure by any participant's performance for that trial. We calculated all statistics on these normalised measures. 

There was no difference between conditions at the start of the experiment in normalised distance (`r apa_print(aov(min_norm_distance ~ learning.condition, sub_walk_all[sub_walk_all$exp_block_id == 1, ]))$statistic$learning_condition`), nor in number errors (`r apa_print(aov(errors ~ learning.condition, sub_walk_all[sub_walk_all$exp_block_id == 1, ]))$statistic$learning_condition`), but there is a significant difference in normalised time (`r apa_print(aov(min_norm_time ~ learning.condition, sub_walk_all[sub_walk_all$exp_block_id == 1, ]))$statistic$learning_condition`)), due to VR taking longer times to get used to (and therefore having longer normalised trial times at the start).

## Participants
```{r}
finished <- overview %>% group_by(condition) %>% count(finished)
finished <- dcast(finished, condition~finished)
finished$percent <- round(finished$yes/(finished$yes+finished$no), 2)
is_ok <- overview %>% filter(finished=="yes") %>% group_by(condition) %>% count(is_ok)
is_ok <- dcast(is_ok, condition~is_ok)
is_ok$percent <- round(is_ok$yes/(is_ok$yes+is_ok$no), 2)
```
A total of `r sum(overview$is_ok == "yes", na.rm=T)` (M = `r round(mean(df_participants[df_participants$finished == "yes",]$age, na.rm=T),1)`, SD = `r round(sd(df_participants[df_participants$finished == "yes",]$age, na.rm=T), 1)`) undergraduate students at UC Davis particiapted in the study in exchange for a study credit. Each students was randomly assigned a condition and a randomised set of goals. `r sum(finished$no)` participants didn't finish due to motion sickness and `r sum(is_ok$no)` were removed due to a technical failure of the real world tracking systen. Only `r finished[finished$condition == "vr-real","percent"] * 100` percent the students being able to finish VR to Real world condition.

# Results

First we wanted to assess that there is going to be some level of transfer in all conditions. If we would assume no transfer to happen, we should observe same performance in the real world testing in 1st, 2nd and 3rd block after the switch to be similar in performance as the 1st, 2nd and 3rd block in the real world learning group. But all conditions (except desktop in distance) show better performance after the switch (see table XXX) than in the first trial, suggesting some level of transfer from all learning conditions.  This is not the case with distance improvement in the desktop learning group.

```{r}
df <- data.frame(condition=rep("",3),dist=rep("",3), err=rep("",3), stringsAsFactors = F)
df_dist <- block_t_test_improvement(sub_walk_all, 1, 4,"min_norm_distance")
df_error <- block_t_test_improvement(sub_walk_all, 1, 4,"errors")
for(i in 1:length(names(df_dist))){
  name <- names(df_dist)[i]
  df[i,"condition"] <- name
  df[i, "dist"] <- apa_print(df_dist[[name]])$full_result
  df[i, "err"] <- apa_print(df_error[[name]])$full_result
}
colnames(df) <- c("Learning condition", "Distance improvement", "Errors improvement")
kable(df, caption="Paired T test comparing individual performance improvement from block 1-4 in different conditions")
```

Looking at the progression in distance improvements and error improvements, we can see that all conditions show improvement over the experiment progression which is only hindered by the switch in the desktop learning condition (see fig. XXX and fig. XXX), but otherwise we see constant improvement unobstructed by the environemnt switch.
```{r}
ggplot(sub_walk_all, aes(learning.condition, min_norm_distance, fill=factor(exp_block_id))) +
  stat_summary(fun.data=mean_cl_normal, position=position_dodge(0.95), geom="errorbar") + 
  stat_summary(fun.y=mean, position=position_dodge(width=0.95), geom="bar") +
  ylab("Average normalised trial distance") + xlab("Learning condition") + 
  scale_fill_manual(values=estimote_pal,"Block ID") + guides(fill=F)

ggplot(sub_walk_all, aes(learning.condition, errors, fill=factor(exp_block_id))) +
  stat_summary(fun.data=mean_cl_normal, position=position_dodge(0.95), geom="errorbar") + 
  stat_summary(fun.y=mean, position=position_dodge(width=0.95), geom="bar") +
  ylab("Average number of errors") + xlab("Learning condition") + 
  scale_fill_manual(values=estimote_pal,"Block ID") + guides(fill=F)
```

Participant's performance in the first pre-switch phase shows different rates of learning rate for errors for our learning conditions (see table XX). There is no significant difference between different modalities in distance performance before the switch `r apa_print(aov(min_norm_distance ~ learning.condition, only_blocks(sub_walk_all, 3)))$full_result`, but the performance across groups differs in errors `r  apa_print(aov(errors ~ learning.condition, only_blocks(sub_walk_all, 3)))$full_result`.

```{r}
learning_slopes_distance <- lmer(min_norm_distance ~ learning.condition*exp_block_id + (1 | id/exp_block_id), data = sub_walk_all[sub_walk_all$exp_block_id %in% 1:3,])

tab_distance <- mixed_table_report(learning_slopes_distance)

learning_slopes_errors <- lmer(errors ~ learning.condition*exp_block_id + (1 | id/exp_block_id), data = sub_walk_all[sub_walk_all$exp_block_id %in% 1:3,])

tab_errors <- mixed_table_report(learning_slopes_distance)
tab <- merge(tab_distance[,c(3,4)], tab_errors[,c(3,4)], by = "names")
colnames(tab) <- c("Predictor", "Significance for distance improvement", "Significance for error improvement")
tab$names <- c("Intercept", "Block number", "Learning condition", "Block - Learning condition interaction")
kable(tab)
#ggplot(sub_walk_all[sub_walk_all$exp_block_id %in% 1:3,], aes(exp_block_id, min_norm_distance, color=learning.condition)) + geom_point() + geom_smooth(method="lm", se=F)

#ggplot(sub_walk_all[sub_walk_all$exp_block_id %in% 1:3,], aes(exp_block_id, errors, color=learning.condition)) + geom_point() + geom_smooth(method="lm", se=F)

```

### After modality switch performance change
Anova doesn't show shows a significant difference between groups in the block 3 (`r apa_print(aov(min_norm_distance ~ learning.condition, sub_walk_all[sub_walk_all$exp_block_id == 3,]))$statistic$learning_condition`), but there is a significant difference between distance performance in the block 4 (`r apa_print(aov(min_norm_distance ~ learning.condition, sub_walk_all[sub_walk_all$exp_block_id == 4,]))$statistic$learning_condition`).

After the switch, we can see a significant difference between distance performance (`r apa_print(aov(min_norm_distance ~ learning.condition, sub_walk_all[sub_walk_all$exp_block_id == 4,]))$statistic$learning_condition`) and errors as well (`r apa_print(aov(errors ~ learning.condition, sub_walk_all[sub_walk_all$exp_block_id == 4,]))$statistic$learning_condition`), with groups learning on the treadmill or desktop performing worse than those learning in the real world.

Mixed effect models with individual random effect show significant effect of the of the learning condition on rate of improvement from phase 1 to pahase 2 (See table XXX )

```{r}
learning_slopes_distance <- lmer(min_norm_distance ~ learning.condition*exp_block_id + (1 | id/exp_block_id), data = only_blocks(sub_walk_all, 3:4))

tab_distance <- mixed_table_report(learning_slopes_distance)

learning_slopes_errors <- lmer(errors ~ learning.condition*exp_block_id + (1 | id/exp_block_id), data = only_blocks(sub_walk_all, 3:4))

tab_errors <- mixed_table_report(learning_slopes_distance)
tab <- merge(tab_distance[,c(3,4)], tab_errors[,c(3,4)], by = "names")
colnames(tab) <- c("Predictor", "Significance for distance improvement", "Significance for error improvement")
tab$names <- c("Intercept", "Block number", "Learning condition", "Block - Learning condition interaction")
kable(tab)
```

Running separate pairwise t-tests to see individual performance change from block 3 to 4 gives the following results.
```{r, echo=F}
df_dist <- block_t_test(sub_walk_all, 3, 4,"min_norm_distance")[,c(1,4)]
df_error <- block_t_test(sub_walk_all, 3, 4,"errors")[,c(1,4)]
df34 <- merge(df_dist, df_error, by = "condition")
colnames(df34) <- c("learning condition", "p-value distance improvement", "p-value errors improvement")
kable(df34, caption="Paired T test comparing infividual performance improvement from block 3-4 in different conditions")
```

We can see that all participants improved in the errors made, but neigher group is significantly worse between block 3 and 4 in the path travelled (although participants learning on desktop perform slightly worse in 4th block, but the significance is only marginal)

### Personal 
To assess the level of performance change form directly before and after the switch, we calculated personal improvement as (block3-block4)/(block3+block4)Â´.

```{r, echo=F}
ggplot(df_distance, aes(x = learning.condition, y = block34.diff, fill = learning.condition)) + 
  geom_bar(stat = 'identity', position="dodge") + 
  geom_errorbar(aes(ymin=block34.diff-block34.se, ymax=block34.diff+block34.se), width=.2, position=position_dodge(.9)) +
  scale_fill_manual(values = estimote_pal) +
  ylab("Mean normalised distance improvement from block 3 to 4") + xlab("Learning condition")  + guides(fill=F)

ggplot(df_errors, aes(x = learning.condition, y = block34.diff, fill = learning.condition)) + 
  geom_bar(stat = 'identity', position="dodge") + 
  geom_errorbar(aes(ymin=block34.diff-block34.se, ymax=block34.diff+block34.se), width=.2, position=position_dodge(.9)) +
  scale_fill_manual(values = estimote_pal) +
  ylab("Mean sum of errors improvement after switch")+ xlab("Learning condition") + guides(fill=F)
```

Comparing the block perfomance change in different conditions using anovas, we see marginally significant difference in the improvement between groups for distance (`r apa_print(aov(block34 ~ learning.condition, df_wide_distance))$statistic$learning_condition`), but we see significant differences in error rate improvement (`r apa_print(aov(block34 ~ learning.condition, df_wide_errors))$statistic$learning_condition`). This is consistent with the mixed models which poited at interaction between block and learning condition.

Tukey post-hoc tests show significant difference between error rate improvement between the group that leardned in the real world and that which learned on the desktop.
```{r, echo=F}
kable(tukey_report(TukeyHSD(x=aov(block34 ~ learning.condition, df_wide_errors), conf.level=0.95)$learning.condition[, c(1,4)]))
```
