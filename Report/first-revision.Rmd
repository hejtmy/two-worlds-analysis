---
title: "1st Revision"
author: "Lukáš Hejtmánek"
date: "20 March 2019"
output: html_document
---

```{r setup, include=FALSE}
#needs lme and car in the top because of the recode
library(car)
library(lme4)
library(ggplot2)
library(gridExtra)
library(ez)
library(Hmisc)
library(dplyr)
library(reshape2)
library(broom)
library(knitr)
library(papaja)
library(googlesheets)

source("../Scripts/paper-prepare.R")
source("../TwoWorlds/helpers-report.R")

settings <- load_google_sheets()
df_participants <- settings$participants
df_participants <- df_participants %>% mutate(condition=paste0(First.phase,"-",Second.phase))

overview <- settings$versions
overview <- overview %>% mutate(condition=paste0(First.phase,"-",Second.phase))
overview <- overview %>% left_join(df_participants[, c('Code', 'sex')], by="Code")

### Try running it without outliers
walk_all[!is.na(walk_all$norm_distance) & walk_all$norm_distance > 3, c("distance", "min_norm_distance")] <- NA

knitr::opts_chunk$set(echo=F, warning = F, message = F)
```

## Dropout rate per gender and condition
```{r}
# need revising 
# is_ok == data well measured
# finished == did finsih, regardless of potentially missing real world data
finished <- overview %>% group_by(condition) %>% count(finished)
finished <- dcast(finished, condition~finished)
finished$percent <- round(finished$yes/(finished$yes+finished$no), 2)

is_ok <- overview %>% filter(finished=="yes") %>% group_by(condition) %>% count(is_ok)
is_ok <- dcast(is_ok, condition~is_ok)
is_ok$percent <- round(is_ok$yes/(is_ok$yes+is_ok$no), 2)
kable(is_ok)
kable(finished)

finished_gender <- overview %>% group_by(condition, sex) %>% count(finished)
finished_gender <- dcast(finished_gender, condition+sex~finished)
finished_gender$no[is.na(finished_gender$no)] <- 0
finished_gender$percent <- round(finished_gender$yes/(finished_gender$yes+finished_gender$no), 2)
kable(finished_gender)
```

## POinting results

### Experiment 1 phase 1
```{r}
summary(aov(abs_error ~ learning.condition, data = sub_sop_all[sub_sop_all$phase == 1, ]))
ggplot(sub_sop_all[sub_sop_all$phase == 1, ], aes(learning.condition, abs_error)) +
  stat_summary(fun.data=mean_cl_normal,position=position_dodge(0.95), geom="errorbar") + 
  stat_summary(fun.y=mean,position=position_dodge(width=0.95),geom="bar")
```

### Experiment 1 phase 2
```{r}
summary(aov(abs_error ~ learning.condition, data = sub_sop_all[sub_sop_all$phase == 2, ]))
ggplot(sub_sop_all[sub_sop_all$phase == 2, ], aes(learning.condition, abs_error)) +
  stat_summary(fun.data=mean_cl_normal,position=position_dodge(0.95), geom="errorbar") + 
  stat_summary(fun.y=mean,position=position_dodge(width=0.95),geom="bar")
```

### Experiment 2 phase 1
```{r}
summary(aov(abs_error ~ learning.condition, data = sub_sop_all_2[sub_sop_all_2$phase == 2, ]))
ggplot(sub_sop_all_2[sub_sop_all_2$phase == 1, ], aes(learning.condition, abs_error)) +
  stat_summary(fun.data=mean_cl_normal,position=position_dodge(0.95), geom="errorbar") + 
  stat_summary(fun.y=mean,position=position_dodge(width=0.95),geom="bar")
```

### Experiment 2 phase 2
```{r}
summary(aov(abs_error ~ learning.condition, data = sub_sop_all_2[sub_sop_all_2$phase == 2, ]))
ggplot(sub_sop_all_2[sub_sop_all_2$phase == 2, ], aes(learning.condition, abs_error)) +
  stat_summary(fun.data=mean_cl_normal,position=position_dodge(0.95), geom="errorbar") + 
  stat_summary(fun.y=mean,position=position_dodge(width=0.95),geom="bar")
```

### Both experiments split by final condition
```{r}
summary(aov(abs_error ~ type, data = sop_all[sop_all$phase == 2, ]))
ggplot(sop_all[sop_all$phase == 2, ], aes(type, abs_error)) +
  stat_summary(fun.data=mean_cl_normal,position=position_dodge(0.95), geom="errorbar") + 
  stat_summary(fun.y=mean,position=position_dodge(width=0.95),geom="bar")
```

### Plot of type to type evolution
```{r}
ggplot(sop_all, aes(phase, abs_error, color=condition)) +
  stat_summary(fun.data=mean_cl_normal,position=position_dodge(0.25), geom="errorbar") + 
  stat_summary(fun.y=mean,position=position_dodge(width=0.25),geom="line")
```
